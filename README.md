ПРОЕКТ ПО ОПРЕДЕЛЕНИЮ КАЛОРИЙНОСТИ БЛЮД С ИСПОЛЬЗОВАНИЕМ МУЛЬТИМОДАЛЬНОГО ИИ (ТЕКСТ + ИЗОБРАЖЕНИЕ)

Активация виртуальной среды, установка зависимостей
# Домашняя машина на windows
# .venv\Scripts\activate.bat 

# Linux
source .venv/bin/activate
pip install -r requirements.txt

# Скачивание сырых данных
python -m src.get_raw_data

# Первый этап обработки - аномалии, джойны
python -m src.clean_data

# Обучение модели
python -m src.train

# Оценка важности каждого модуля
python -m src.ablation

# Визуализации обучения
python -m src.train_viz

ВЫВОДЫ

Получены удоволетворительные результаты при использовании мультимодального ИИ для определения калорийности блюда по списку ингредиентов. фото и массе блюда. Для выполнения задачи был взят BERT для текстового списка ингредиентов, tf_efficientnet_b7 для анализа фотографий (с агументациями). Были разморожены несколько верхних слоёв (у BERT предпоследний и последние слои в базе и слой для агрегации финального представления в токен CLS, у CNN - последний сверточный блок, финальный сверточный слой перед классификацией и слой нормализации батчей). Минимальная MAE на валидации получилась около 40ккал. Переобучения удалось избежать. В теории можно добиться улучшений еще большими аугментациями картинок. Аугментации текста только мусорят, т.к. особо синонимов в еде не подберешь, а обратный перевод приводит к неожиданным и даже неверным результатам. ViT для визуальной части дал худшие результаты, возможно, потому что ему нужно больших данных. Способность модели объяснить вариации в данных (R^2) около 0.9, это хорший результат. Для модели в целом оказалась важнее тектовая модальность, как показал результат абляции. Посмотерть на визуализацию обучения можно здесь C:\Users\Alexandra\Desktop\multimodal_calorie_count\logs\training_visualization.png.